{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d67730b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27cede41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## count the number of characters\n",
    "def count_chars(text):\n",
    "    return len(text)\n",
    "\n",
    "## count the number of words\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "## count the number of sentences\n",
    "def count_sent(text):\n",
    "    return len(nltk.sent_tokenize(text))\n",
    "\n",
    "## count the number of unique words within the tweet\n",
    "def count_unique(text):\n",
    "    return len(set(text.split()))\n",
    "\n",
    "## count hashtags\n",
    "def count_htags(text):\n",
    "    return len(re.findall(r'(#w[A-Za-z0-9]*)', text))\n",
    "\n",
    "## count capital letters\n",
    "def count_capital_chars(text):\n",
    "    count = 0\n",
    "    for x in text:\n",
    "        if x.isupper():\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "## count capital words\n",
    "def count_capital_words(text):\n",
    "    return sum(map(str.isupper, text.split()))\n",
    "\n",
    "## count number of punctuations\n",
    "def count_punctuations(text):\n",
    "    d=dict()\n",
    "    for i in string.punctuation:\n",
    "        d[str(i)+' count']=text.count(i)\n",
    "    return d\n",
    "\n",
    "## count stopwords\n",
    "def count_stopwords(text):\n",
    "    ## not sure how to do\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "239f823e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\sample_submission.csv\n",
      ".\\data\\test.csv\n",
      ".\\data\\train.csv\n",
      "load data done\n",
      "test :(3263, 4)\n",
      "training: (7613, 5)\n",
      "total keywords NA: 221\n",
      "total locations NA:3341\n"
     ]
    }
   ],
   "source": [
    "    for dirname, _, filenames in os.walk('.\\data'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "    train = pd.read_csv('./data/train.csv')\n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    print(\"load data done\")\n",
    "    print('test :' + str(test.shape))\n",
    "    \n",
    "    print('training: ' + str(train.shape))\n",
    "    print('total keywords NA: ' + str(train.keyword.nunique()))\n",
    "    print('total locations NA:' + str(train.location.nunique()))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8db3757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # make feature columns\n",
    "    train['char_count'] = train['text'].apply(lambda x:count_chars(x))\n",
    "    train['word_count'] = train['text'].apply(lambda x:count_words(x))\n",
    "    train['sent_count'] = train['text'].apply(lambda x:count_sent(x))\n",
    "    train['cap_char_count'] = train['text'].apply(lambda x:count_capital_chars(x))\n",
    "    train['cap_word_count'] = train['text'].apply(lambda x:count_capital_words(x))\n",
    "    train['unique_word_count'] = train['text'].apply(lambda x:count_unique(x))\n",
    "    train['htag_count'] = train['text'].apply(lambda x:count_htags(x))\n",
    "    train['punct_count'] = train['text'].apply(lambda x:count_punctuations(x))\n",
    "    # average word length\n",
    "    train['avg_word_length'] = train['char_count']/train['word_count']\n",
    "    # average sentence length\n",
    "    train['avg_sentence_length'] = train['word_count']/train['sent_count']\n",
    "    # fraction of unique to total words\n",
    "    train['unique_v_words'] = train['unique_word_count']/train['word_count']\n",
    "    # adding punctuation as features columns\n",
    "    train_punct = pd.DataFrame(list(train.punct_count))\n",
    "    train = pd.merge(train, train_punct, left_index=True, right_index=True)\n",
    "    train.drop(columns=['punct_count'], inplace=True)\n",
    "    \n",
    "    test['char_count'] = test['text'].apply(lambda x:count_chars(x))\n",
    "    test['word_count'] = test['text'].apply(lambda x:count_words(x))\n",
    "    test['sent_count'] = test['text'].apply(lambda x:count_sent(x))\n",
    "    test['cap_char_count'] = test['text'].apply(lambda x:count_capital_chars(x))\n",
    "    test['cap_word_count'] = test['text'].apply(lambda x:count_capital_words(x))\n",
    "    test['unique_word_count'] = test['text'].apply(lambda x:count_unique(x))\n",
    "    test['htag_count'] = test['text'].apply(lambda x:count_htags(x))\n",
    "    test['punct_count'] = test['text'].apply(lambda x:count_punctuations(x))\n",
    "    test['avg_word_length'] = test['char_count']/train['word_count']\n",
    "    test['avg_sentence_length'] = test['word_count']/train['sent_count']\n",
    "    test['unique_v_words'] = test['unique_word_count']/train['word_count']\n",
    "    test_punct = pd.DataFrame(list(test.punct_count))\n",
    "    test = pd.merge(test, test_punct, left_index=True, right_index=True)\n",
    "    test.drop(columns=['punct_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a41288c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  char_count  word_count  sent_count  cap_char_count  cap_word_count  \\\n",
      "0       1          69          13           1              10               1   \n",
      "1       1          38           7           2               5               0   \n",
      "2       1         133          22           2               2               0   \n",
      "3       1          65           8           1               1               0   \n",
      "4       1          88          16           1               3               0   \n",
      "\n",
      "   ...  [ count  \\ count  ] count  ^ count  _ count  ` count  { count  \\\n",
      "0  ...        0        0        0        0        0        0        0   \n",
      "1  ...        0        0        0        0        0        0        0   \n",
      "2  ...        0        0        0        0        0        0        0   \n",
      "3  ...        0        0        0        0        0        0        0   \n",
      "4  ...        0        0        0        0        0        0        0   \n",
      "\n",
      "   | count  } count  ~ count  \n",
      "0        0        0        0  \n",
      "1        0        0        0  \n",
      "2        0        0        0  \n",
      "3        0        0        0  \n",
      "4        0        0        0  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a109085b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
